{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Binary Classification using Perception, MLP and Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem\n",
    "\n",
    "    Is to identify products at risk of backorder before the event occurs so the business has time to react. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data\n",
    "\n",
    "Data file contains the historical data for the 8 weeks prior to the week we are trying to predict. The data was taken as weekly snapshots at the start of each week. Columns are defined as follows:\n",
    "\n",
    "    sku - Random ID for the product\n",
    "\n",
    "    national_inv - Current inventory level for the part\n",
    "\n",
    "    lead_time - Transit time for product (if available)\n",
    "\n",
    "    in_transit_qty - Amount of product in transit from source\n",
    "\n",
    "    forecast_3_month - Forecast sales for the next 3 months\n",
    "\n",
    "    forecast_6_month - Forecast sales for the next 6 months\n",
    "\n",
    "    forecast_9_month - Forecast sales for the next 9 months\n",
    "\n",
    "    sales_1_month - Sales quantity for the prior 1 month time period\n",
    "\n",
    "    sales_3_month - Sales quantity for the prior 3 month time period\n",
    "\n",
    "    sales_6_month - Sales quantity for the prior 6 month time period\n",
    "\n",
    "    sales_9_month - Sales quantity for the prior 9 month time period\n",
    "\n",
    "    min_bank - Minimum recommend amount to stock\n",
    "\n",
    "    potential_issue - Source issue for part identified\n",
    "\n",
    "    pieces_past_due - Parts overdue from source\n",
    "\n",
    "    perf_6_month_avg - Source performance for prior 6 month period\n",
    "\n",
    "    perf_12_month_avg - Source performance for prior 12 month period\n",
    "\n",
    "    local_bo_qty - Amount of stock orders overdue\n",
    "\n",
    "    deck_risk - Part risk flag\n",
    "\n",
    "    oe_constraint - Part risk flag\n",
    "\n",
    "    ppap_risk - Part risk flag\n",
    "\n",
    "    stop_auto_buy - Part risk flag\n",
    "\n",
    "    rev_stop - Part risk flag\n",
    "\n",
    "    went_on_backorder - Product actually went on backorder. This is the target value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify Right Error Metrics\n",
    "\n",
    "    Based on the businees have to identify right error metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/datasets/lab/DT_BackOrders.csv\",header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understand the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the No. row and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61589, 23)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sku', 'national_inv', 'lead_time', 'in_transit_qty',\n",
       "       'forecast_3_month', 'forecast_6_month', 'forecast_9_month',\n",
       "       'sales_1_month', 'sales_3_month', 'sales_6_month', 'sales_9_month',\n",
       "       'min_bank', 'potential_issue', 'pieces_past_due', 'perf_6_month_avg',\n",
       "       'perf_12_month_avg', 'local_bo_qty', 'deck_risk', 'oe_constraint',\n",
       "       'ppap_risk', 'stop_auto_buy', 'rev_stop', 'went_on_backorder'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=61589, step=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the top rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>national_inv</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>in_transit_qty</th>\n",
       "      <th>forecast_3_month</th>\n",
       "      <th>forecast_6_month</th>\n",
       "      <th>forecast_9_month</th>\n",
       "      <th>sales_1_month</th>\n",
       "      <th>sales_3_month</th>\n",
       "      <th>sales_6_month</th>\n",
       "      <th>...</th>\n",
       "      <th>pieces_past_due</th>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <th>local_bo_qty</th>\n",
       "      <th>deck_risk</th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "      <th>went_on_backorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1888279</td>\n",
       "      <td>117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1870557</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1475481</td>\n",
       "      <td>258</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>77</td>\n",
       "      <td>184</td>\n",
       "      <td>46</td>\n",
       "      <td>132</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sku  national_inv  lead_time  in_transit_qty  forecast_3_month  \\\n",
       "0  1888279           117        NaN               0                 0   \n",
       "1  1870557             7        2.0               0                 0   \n",
       "2  1475481           258       15.0              10                10   \n",
       "\n",
       "   forecast_6_month  forecast_9_month  sales_1_month  sales_3_month  \\\n",
       "0                 0                 0              0              0   \n",
       "1                 0                 0              0              0   \n",
       "2                77               184             46            132   \n",
       "\n",
       "   sales_6_month  ...  pieces_past_due  perf_6_month_avg perf_12_month_avg  \\\n",
       "0             15  ...                0            -99.00            -99.00   \n",
       "1              0  ...                0              0.50              0.28   \n",
       "2            256  ...                0              0.54              0.70   \n",
       "\n",
       "   local_bo_qty  deck_risk  oe_constraint  ppap_risk stop_auto_buy rev_stop  \\\n",
       "0             0         No             No        Yes           Yes       No   \n",
       "1             0        Yes             No         No           Yes       No   \n",
       "2             0         No             No         No           Yes       No   \n",
       "\n",
       "  went_on_backorder  \n",
       "0                No  \n",
       "1                No  \n",
       "2                No  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows a quick statistic summary of your data using describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>national_inv</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>in_transit_qty</th>\n",
       "      <th>forecast_3_month</th>\n",
       "      <th>forecast_6_month</th>\n",
       "      <th>forecast_9_month</th>\n",
       "      <th>sales_1_month</th>\n",
       "      <th>sales_3_month</th>\n",
       "      <th>sales_6_month</th>\n",
       "      <th>...</th>\n",
       "      <th>pieces_past_due</th>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <th>local_bo_qty</th>\n",
       "      <th>deck_risk</th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "      <th>went_on_backorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.158900e+04</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>58186.000000</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>6.158900e+04</td>\n",
       "      <td>6.158900e+04</td>\n",
       "      <td>6.158900e+04</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>6.158900e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>61589</td>\n",
       "      <td>61589</td>\n",
       "      <td>61589</td>\n",
       "      <td>61589</td>\n",
       "      <td>61589</td>\n",
       "      <td>61589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48145</td>\n",
       "      <td>61577</td>\n",
       "      <td>53792</td>\n",
       "      <td>59303</td>\n",
       "      <td>61569</td>\n",
       "      <td>50296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.037188e+06</td>\n",
       "      <td>287.721882</td>\n",
       "      <td>7.559619</td>\n",
       "      <td>30.192843</td>\n",
       "      <td>1.692728e+02</td>\n",
       "      <td>3.150413e+02</td>\n",
       "      <td>4.535760e+02</td>\n",
       "      <td>44.742957</td>\n",
       "      <td>150.732631</td>\n",
       "      <td>2.835465e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.605400</td>\n",
       "      <td>-6.264182</td>\n",
       "      <td>-5.863664</td>\n",
       "      <td>1.205361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.564178e+05</td>\n",
       "      <td>4233.906931</td>\n",
       "      <td>6.498952</td>\n",
       "      <td>792.869253</td>\n",
       "      <td>5.286742e+03</td>\n",
       "      <td>9.774362e+03</td>\n",
       "      <td>1.420201e+04</td>\n",
       "      <td>1373.805831</td>\n",
       "      <td>5224.959649</td>\n",
       "      <td>8.872270e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>42.309229</td>\n",
       "      <td>25.537906</td>\n",
       "      <td>24.844514</td>\n",
       "      <td>29.981155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.068628e+06</td>\n",
       "      <td>-2999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.498574e+06</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.898033e+06</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.314826e+06</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>3.600000e+01</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.400000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.284895e+06</td>\n",
       "      <td>673445.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>170976.000000</td>\n",
       "      <td>1.126656e+06</td>\n",
       "      <td>2.094336e+06</td>\n",
       "      <td>3.062016e+06</td>\n",
       "      <td>295197.000000</td>\n",
       "      <td>934593.000000</td>\n",
       "      <td>1.799099e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>7392.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2999.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 sku   national_inv     lead_time  in_transit_qty  \\\n",
       "count   6.158900e+04   61589.000000  58186.000000    61589.000000   \n",
       "unique           NaN            NaN           NaN             NaN   \n",
       "top              NaN            NaN           NaN             NaN   \n",
       "freq             NaN            NaN           NaN             NaN   \n",
       "mean    2.037188e+06     287.721882      7.559619       30.192843   \n",
       "std     6.564178e+05    4233.906931      6.498952      792.869253   \n",
       "min     1.068628e+06   -2999.000000      0.000000        0.000000   \n",
       "25%     1.498574e+06       3.000000      4.000000        0.000000   \n",
       "50%     1.898033e+06      10.000000      8.000000        0.000000   \n",
       "75%     2.314826e+06      57.000000      8.000000        0.000000   \n",
       "max     3.284895e+06  673445.000000     52.000000   170976.000000   \n",
       "\n",
       "        forecast_3_month  forecast_6_month  forecast_9_month  sales_1_month  \\\n",
       "count       6.158900e+04      6.158900e+04      6.158900e+04   61589.000000   \n",
       "unique               NaN               NaN               NaN            NaN   \n",
       "top                  NaN               NaN               NaN            NaN   \n",
       "freq                 NaN               NaN               NaN            NaN   \n",
       "mean        1.692728e+02      3.150413e+02      4.535760e+02      44.742957   \n",
       "std         5.286742e+03      9.774362e+03      1.420201e+04    1373.805831   \n",
       "min         0.000000e+00      0.000000e+00      0.000000e+00       0.000000   \n",
       "25%         0.000000e+00      0.000000e+00      0.000000e+00       0.000000   \n",
       "50%         0.000000e+00      0.000000e+00      0.000000e+00       0.000000   \n",
       "75%         1.200000e+01      2.500000e+01      3.600000e+01       6.000000   \n",
       "max         1.126656e+06      2.094336e+06      3.062016e+06  295197.000000   \n",
       "\n",
       "        sales_3_month  sales_6_month  ...  pieces_past_due  perf_6_month_avg  \\\n",
       "count    61589.000000   6.158900e+04  ...     61589.000000      61589.000000   \n",
       "unique            NaN            NaN  ...              NaN               NaN   \n",
       "top               NaN            NaN  ...              NaN               NaN   \n",
       "freq              NaN            NaN  ...              NaN               NaN   \n",
       "mean       150.732631   2.835465e+02  ...         1.605400         -6.264182   \n",
       "std       5224.959649   8.872270e+03  ...        42.309229         25.537906   \n",
       "min          0.000000   0.000000e+00  ...         0.000000        -99.000000   \n",
       "25%          0.000000   0.000000e+00  ...         0.000000          0.620000   \n",
       "50%          2.000000   4.000000e+00  ...         0.000000          0.820000   \n",
       "75%         17.000000   3.400000e+01  ...         0.000000          0.960000   \n",
       "max     934593.000000   1.799099e+06  ...      7392.000000          1.000000   \n",
       "\n",
       "       perf_12_month_avg  local_bo_qty  deck_risk  oe_constraint  ppap_risk  \\\n",
       "count       61589.000000  61589.000000      61589          61589      61589   \n",
       "unique               NaN           NaN          2              2          2   \n",
       "top                  NaN           NaN         No             No         No   \n",
       "freq                 NaN           NaN      48145          61577      53792   \n",
       "mean           -5.863664      1.205361        NaN            NaN        NaN   \n",
       "std            24.844514     29.981155        NaN            NaN        NaN   \n",
       "min           -99.000000      0.000000        NaN            NaN        NaN   \n",
       "25%             0.640000      0.000000        NaN            NaN        NaN   \n",
       "50%             0.800000      0.000000        NaN            NaN        NaN   \n",
       "75%             0.950000      0.000000        NaN            NaN        NaN   \n",
       "max             1.000000   2999.000000        NaN            NaN        NaN   \n",
       "\n",
       "       stop_auto_buy rev_stop went_on_backorder  \n",
       "count          61589    61589             61589  \n",
       "unique             2        2                 2  \n",
       "top              Yes       No                No  \n",
       "freq           59303    61569             50296  \n",
       "mean             NaN      NaN               NaN  \n",
       "std              NaN      NaN               NaN  \n",
       "min              NaN      NaN               NaN  \n",
       "25%              NaN      NaN               NaN  \n",
       "50%              NaN      NaN               NaN  \n",
       "75%              NaN      NaN               NaN  \n",
       "max              NaN      NaN               NaN  \n",
       "\n",
       "[11 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display data type of each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sku                    int64\n",
       "national_inv           int64\n",
       "lead_time            float64\n",
       "in_transit_qty         int64\n",
       "forecast_3_month       int64\n",
       "forecast_6_month       int64\n",
       "forecast_9_month       int64\n",
       "sales_1_month          int64\n",
       "sales_3_month          int64\n",
       "sales_6_month          int64\n",
       "sales_9_month          int64\n",
       "min_bank               int64\n",
       "potential_issue       object\n",
       "pieces_past_due        int64\n",
       "perf_6_month_avg     float64\n",
       "perf_12_month_avg    float64\n",
       "local_bo_qty           int64\n",
       "deck_risk             object\n",
       "oe_constraint         object\n",
       "ppap_risk             object\n",
       "stop_auto_buy         object\n",
       "rev_stop              object\n",
       "went_on_backorder     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "    sku is Categorical but is interpreted as int64 \n",
    "    potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_buy, rev_stop, and went_on_backorder are also categorical but is interpreted as object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert all the attributes to appropriate type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data type conversion\n",
    "\n",
    "    Using astype('category') to convert potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_buy, rev_stop, and went_on_backorder attributes to categorical attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['sku', 'potential_issue', 'deck_risk', 'oe_constraint', 'ppap_risk', 'stop_auto_buy', 'rev_stop', 'went_on_backorder']:\n",
    "    data[col] = data[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display data type of each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sku                  category\n",
       "national_inv            int64\n",
       "lead_time             float64\n",
       "in_transit_qty          int64\n",
       "forecast_3_month        int64\n",
       "forecast_6_month        int64\n",
       "forecast_9_month        int64\n",
       "sales_1_month           int64\n",
       "sales_3_month           int64\n",
       "sales_6_month           int64\n",
       "sales_9_month           int64\n",
       "min_bank                int64\n",
       "potential_issue      category\n",
       "pieces_past_due         int64\n",
       "perf_6_month_avg      float64\n",
       "perf_12_month_avg     float64\n",
       "local_bo_qty            int64\n",
       "deck_risk            category\n",
       "oe_constraint        category\n",
       "ppap_risk            category\n",
       "stop_auto_buy        category\n",
       "rev_stop             category\n",
       "went_on_backorder    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete sku attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61589"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(np.unique(data.sku, return_counts=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('sku', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Data\n",
    "\n",
    "    Missing value analysis and dropping the records with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "national_inv            0\n",
       "lead_time            3403\n",
       "in_transit_qty          0\n",
       "forecast_3_month        0\n",
       "forecast_6_month        0\n",
       "forecast_9_month        0\n",
       "sales_1_month           0\n",
       "sales_3_month           0\n",
       "sales_6_month           0\n",
       "sales_9_month           0\n",
       "min_bank                0\n",
       "potential_issue         0\n",
       "pieces_past_due         0\n",
       "perf_6_month_avg        0\n",
       "perf_12_month_avg       0\n",
       "local_bo_qty            0\n",
       "deck_risk               0\n",
       "oe_constraint           0\n",
       "ppap_risk               0\n",
       "stop_auto_buy           0\n",
       "rev_stop                0\n",
       "went_on_backorder       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the number of records before and after missing value records removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61589, 22)\n"
     ]
    }
   ],
   "source": [
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the number of missing values is about 5%. For initial analysis we ignore all these records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58186, 22)\n"
     ]
    }
   ],
   "source": [
    "data.isnull().sum()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Categorical to Numeric\n",
    "\n",
    "For some of the models all the independent attribute should be of type numeric and Linear Regression model is one among them.\n",
    "But this data set has some categorial attributes.\n",
    "\n",
    "'pandas.get_dummies' To convert convert categorical variable into dummy/indicator variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['national_inv', 'lead_time', 'in_transit_qty', 'forecast_3_month',\n",
      "       'forecast_6_month', 'forecast_9_month', 'sales_1_month',\n",
      "       'sales_3_month', 'sales_6_month', 'sales_9_month', 'min_bank',\n",
      "       'potential_issue', 'pieces_past_due', 'perf_6_month_avg',\n",
      "       'perf_12_month_avg', 'local_bo_qty', 'deck_risk', 'oe_constraint',\n",
      "       'ppap_risk', 'stop_auto_buy', 'rev_stop', 'went_on_backorder'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print (data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dummy variables.\n",
    "\n",
    "    If we have k levels in a category, then we create k-1 dummy variables as the last one would be redundant. So we use the parameter drop_first in pd.get_dummies function that drops the first level in each of the category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_Attributes = data.select_dtypes(include=['category']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(columns=categorical_Attributes, data=data, prefix=categorical_Attributes, prefix_sep=\"_\",drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['national_inv', 'lead_time', 'in_transit_qty', 'forecast_3_month',\n",
      "       'forecast_6_month', 'forecast_9_month', 'sales_1_month',\n",
      "       'sales_3_month', 'sales_6_month', 'sales_9_month', 'min_bank',\n",
      "       'pieces_past_due', 'perf_6_month_avg', 'perf_12_month_avg',\n",
      "       'local_bo_qty', 'potential_issue_Yes', 'deck_risk_Yes',\n",
      "       'oe_constraint_Yes', 'ppap_risk_Yes', 'stop_auto_buy_Yes',\n",
      "       'rev_stop_Yes', 'went_on_backorder_Yes'],\n",
      "      dtype='object') (58186, 22)\n"
     ]
    }
   ],
   "source": [
    "print (data.columns, data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target attribute distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    47217\n",
       "1    10969\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(data['went_on_backorder_Yes'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data in to train and test\n",
    "\n",
    "sklearn.model_selection.train_test_split\n",
    "\n",
    "    Split arrays or matrices into random train and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing train test split on the data\n",
    "X, y = data.loc[:,data.columns!='went_on_backorder_Yes'].values, data.loc[:,'went_on_backorder_Yes'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    33067\n",
      "1     7663\n",
      "dtype: int64\n",
      "0    14150\n",
      "1     3306\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#To get the distribution in the target in train and test\n",
    "print(pd.value_counts(y_train))\n",
    "print(pd.value_counts(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_model = Sequential()\n",
    "\n",
    "perceptron_model.add(Dense(1, input_dim=X_train.shape[1], activation='sigmoid', kernel_initializer='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 22        \n",
      "=================================================================\n",
      "Total params: 22\n",
      "Trainable params: 22\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "perceptron_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1273/1273 [==============================] - 2s 925us/step - loss: 1.2334\n",
      "Epoch 2/100\n",
      "1273/1273 [==============================] - 1s 990us/step - loss: 1.9043 0s - loss - ETA: 0s - loss: 1\n",
      "Epoch 3/100\n",
      "1273/1273 [==============================] - 1s 739us/step - loss: 1.1566\n",
      "Epoch 4/100\n",
      "1273/1273 [==============================] - 1s 781us/step - loss: 0.8733 0s - los\n",
      "Epoch 5/100\n",
      "1273/1273 [==============================] - 1s 821us/step - loss: 0.9279\n",
      "Epoch 6/100\n",
      "1273/1273 [==============================] - 1s 828us/step - loss: 1.0194\n",
      "Epoch 7/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 1.9256\n",
      "Epoch 8/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 2.2561\n",
      "Epoch 9/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 1.0457\n",
      "Epoch 10/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 0.8028\n",
      "Epoch 11/100\n",
      "1273/1273 [==============================] - 1s 991us/step - loss: 1.7582\n",
      "Epoch 12/100\n",
      "1273/1273 [==============================] - 1s 890us/step - loss: 0.9843\n",
      "Epoch 13/100\n",
      "1273/1273 [==============================] - 1s 896us/step - loss: 0.8526\n",
      "Epoch 14/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 1.1272\n",
      "Epoch 15/100\n",
      "1273/1273 [==============================] - 1s 914us/step - loss: 0.9528\n",
      "Epoch 16/100\n",
      "1273/1273 [==============================] - 1s 910us/step - loss: 1.1010\n",
      "Epoch 17/100\n",
      "1273/1273 [==============================] - 1s 986us/step - loss: 0.7416\n",
      "Epoch 18/100\n",
      "1273/1273 [==============================] - 1s 927us/step - loss: 2.4924\n",
      "Epoch 19/100\n",
      "1273/1273 [==============================] - 1s 972us/step - loss: 0.6797\n",
      "Epoch 20/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 0.9630\n",
      "Epoch 21/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 1.8496\n",
      "Epoch 22/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 0.8392\n",
      "Epoch 23/100\n",
      "1273/1273 [==============================] - 1s 868us/step - loss: 0.8238\n",
      "Epoch 24/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 0.7232\n",
      "Epoch 25/100\n",
      "1273/1273 [==============================] - 1s 930us/step - loss: 0.7005\n",
      "Epoch 26/100\n",
      "1273/1273 [==============================] - 1s 754us/step - loss: 1.1067\n",
      "Epoch 27/100\n",
      "1273/1273 [==============================] - 1s 871us/step - loss: 0.8424\n",
      "Epoch 28/100\n",
      "1273/1273 [==============================] - 1s 857us/step - loss: 0.9242\n",
      "Epoch 29/100\n",
      "1273/1273 [==============================] - 1s 796us/step - loss: 0.9480\n",
      "Epoch 30/100\n",
      "1273/1273 [==============================] - ETA: 0s - loss: 1.037 - 1s 829us/step - loss: 1.0419\n",
      "Epoch 31/100\n",
      "1273/1273 [==============================] - 1s 910us/step - loss: 0.8661 0s - los\n",
      "Epoch 32/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 0.7884\n",
      "Epoch 33/100\n",
      "1273/1273 [==============================] - 1s 932us/step - loss: 1.0967 0s - loss: 1.086\n",
      "Epoch 34/100\n",
      "1273/1273 [==============================] - 1s 944us/step - loss: 0.9517\n",
      "Epoch 35/100\n",
      "1273/1273 [==============================] - 1s 844us/step - loss: 0.7517\n",
      "Epoch 36/100\n",
      "1273/1273 [==============================] - 1s 715us/step - loss: 0.8535\n",
      "Epoch 37/100\n",
      "1273/1273 [==============================] - 1s 762us/step - loss: 1.2087\n",
      "Epoch 38/100\n",
      "1273/1273 [==============================] - 1s 845us/step - loss: 1.2242\n",
      "Epoch 39/100\n",
      "1273/1273 [==============================] - 1s 992us/step - loss: 1.1670\n",
      "Epoch 40/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 0.9582\n",
      "Epoch 41/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 1.6802\n",
      "Epoch 42/100\n",
      "1273/1273 [==============================] - 1s 902us/step - loss: 0.6179\n",
      "Epoch 43/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 0.9828\n",
      "Epoch 44/100\n",
      "1273/1273 [==============================] - 1s 890us/step - loss: 1.4505\n",
      "Epoch 45/100\n",
      "1273/1273 [==============================] - 1s 912us/step - loss: 1.0445\n",
      "Epoch 46/100\n",
      "1273/1273 [==============================] - 1s 978us/step - loss: 1.1213\n",
      "Epoch 47/100\n",
      "1273/1273 [==============================] - 1s 986us/step - loss: 1.2339\n",
      "Epoch 48/100\n",
      "1273/1273 [==============================] - 1s 986us/step - loss: 1.0313\n",
      "Epoch 49/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 0.8382\n",
      "Epoch 50/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.8472\n",
      "Epoch 51/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 1.6751\n",
      "Epoch 52/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 1.8144\n",
      "Epoch 53/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 1.3331\n",
      "Epoch 54/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 1.0618\n",
      "Epoch 55/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.8017\n",
      "Epoch 56/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 0.7625\n",
      "Epoch 57/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.8032\n",
      "Epoch 58/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 1.0289\n",
      "Epoch 59/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 1.8155\n",
      "Epoch 60/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 0.7226\n",
      "Epoch 61/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 1.5942\n",
      "Epoch 62/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 1.0367\n",
      "Epoch 63/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 1.1609\n",
      "Epoch 64/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 1.0837\n",
      "Epoch 65/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 0.8127\n",
      "Epoch 66/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 0.7730\n",
      "Epoch 67/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 1.3040\n",
      "Epoch 68/100\n",
      "1273/1273 [==============================] - 1s 999us/step - loss: 1.2111\n",
      "Epoch 69/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 0.8328\n",
      "Epoch 70/100\n",
      "1273/1273 [==============================] - 1s 989us/step - loss: 0.8232\n",
      "Epoch 71/100\n",
      "1273/1273 [==============================] - 1s 830us/step - loss: 0.8858\n",
      "Epoch 72/100\n",
      "1273/1273 [==============================] - 1s 933us/step - loss: 1.5204\n",
      "Epoch 73/100\n",
      "1273/1273 [==============================] - 1s 803us/step - loss: 0.8339\n",
      "Epoch 74/100\n",
      "1273/1273 [==============================] - 1s 964us/step - loss: 0.7666\n",
      "Epoch 75/100\n",
      "1273/1273 [==============================] - 1s 970us/step - loss: 0.7283\n",
      "Epoch 76/100\n",
      "1273/1273 [==============================] - 1s 829us/step - loss: 0.9387\n",
      "Epoch 77/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.8655\n",
      "Epoch 78/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 0.7580\n",
      "Epoch 79/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 1.4109\n",
      "Epoch 80/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 0.7846\n",
      "Epoch 81/100\n",
      "1273/1273 [==============================] - 1s 876us/step - loss: 0.8967\n",
      "Epoch 82/100\n",
      "1273/1273 [==============================] - 1s 813us/step - loss: 2.9746\n",
      "Epoch 83/100\n",
      "1273/1273 [==============================] - 1s 926us/step - loss: 0.6511\n",
      "Epoch 84/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 0.9504\n",
      "Epoch 85/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 1.7069\n",
      "Epoch 86/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.8216\n",
      "Epoch 87/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 1.1839A: 0s - loss: 1.181\n",
      "Epoch 88/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 0.8454\n",
      "Epoch 89/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 1.0703\n",
      "Epoch 90/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 1.0034\n",
      "Epoch 91/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 1.2070\n",
      "Epoch 92/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 1.2560\n",
      "Epoch 93/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 1.0118\n",
      "Epoch 94/100\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.8649\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.7524\n",
      "Epoch 96/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 1.0437\n",
      "Epoch 97/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 1.1947\n",
      "Epoch 98/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 1.0221\n",
      "Epoch 99/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 1.5547\n",
      "Epoch 100/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 1.6427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa734315310>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron_model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "test_pred=perceptron_model.predict_classes(X_test)\n",
    "train_pred=perceptron_model.predict_classes(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting evaluation metrics and evaluating model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32702   365]\n",
      " [ 6468  1195]]\n",
      "[[13987   163]\n",
      " [ 2801   505]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_test = confusion_matrix(y_test, test_pred)\n",
    "confusion_matrix_train = confusion_matrix(y_train, train_pred)\n",
    "\n",
    "print(confusion_matrix_train)\n",
    "print(confusion_matrix_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Accuracy, True Positive Rate and True Negative Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train TNR:  0.9889618048205159\n",
      "Train TPR:  0.1559441472008352\n",
      "Train Accuracy:  0.8322366805794255\n"
     ]
    }
   ],
   "source": [
    "Accuracy_Train = (confusion_matrix_train[0,0]+confusion_matrix_train[1,1])/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1]+confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "TNR_Train = confusion_matrix_train[0,0]/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1])\n",
    "TPR_Train = confusion_matrix_train[1,1]/(confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "\n",
    "print(\"Train TNR: \",TNR_Train)\n",
    "print(\"Train TPR: \",TPR_Train)\n",
    "print(\"Train Accuracy: \",Accuracy_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test TNR:  0.9884805653710247\n",
      "Test TPR:  0.15275257108287962\n",
      "Test Accuracy:  0.8302016498625114\n"
     ]
    }
   ],
   "source": [
    "Accuracy_Test = (confusion_matrix_test[0,0]+confusion_matrix_test[1,1])/(confusion_matrix_test[0,0]+confusion_matrix_test[0,1]+confusion_matrix_test[1,0]+confusion_matrix_test[1,1])\n",
    "TNR_Test = confusion_matrix_test[0,0]/(confusion_matrix_test[0,0] +confusion_matrix_test[0,1])\n",
    "TPR_Test = confusion_matrix_test[1,1]/(confusion_matrix_test[1,0] +confusion_matrix_test[1,1])\n",
    "\n",
    "print(\"Test TNR: \",TNR_Test)\n",
    "print(\"Test TPR: \",TPR_Test)\n",
    "print(\"Test Accuracy: \",Accuracy_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derive new non-linear features using autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The size of encoded and actual representations\n",
    "encoding_dim = 16 \n",
    "actual_dim = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input placeholder\n",
    "input_attrs = Input(shape=(actual_dim,))\n",
    "\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_attrs)\n",
    "\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(actual_dim, activation='sigmoid')(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_attrs, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 21)]              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                352       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 21)                357       \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(autoencoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -26577717.6501A: 0s - loss: -27507\n",
      "Epoch 2/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -27629986.7584\n",
      "Epoch 3/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -201953637.9185\n",
      "Epoch 4/100\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: -30035467.6425\n",
      "Epoch 5/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -344395339.7863\n",
      "Epoch 6/100\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: -342929999.6622\n",
      "Epoch 7/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -228064267.0427\n",
      "Epoch 8/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -781294300.8020\n",
      "Epoch 9/100\n",
      "1273/1273 [==============================] - 1s 991us/step - loss: -596244520.6020\n",
      "Epoch 10/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -103951829.2950\n",
      "Epoch 11/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -683517957.1368\n",
      "Epoch 12/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -149916159.0672\n",
      "Epoch 13/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -95613499.5055\n",
      "Epoch 14/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -1433736017.8642A: 0s - los\n",
      "Epoch 15/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -3368039269.2891\n",
      "Epoch 16/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -826439286.8857\n",
      "Epoch 17/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -328774988.7080\n",
      "Epoch 18/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -859384092.1317\n",
      "Epoch 19/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -2835972695.7017\n",
      "Epoch 20/100\n",
      "1273/1273 [==============================] - 1s 918us/step - loss: -1086417183.9674\n",
      "Epoch 21/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -675242779.7017\n",
      "Epoch 22/100\n",
      "1273/1273 [==============================] - 1s 994us/step - loss: -2484548215.4989\n",
      "Epoch 23/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -589339631.6375\n",
      "Epoch 24/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -4798021774.3107\n",
      "Epoch 25/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -908096305.1146: 1s - loss: -390613881. - ETA: 1s - loss: - ETA: 0s - los\n",
      "Epoch 26/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -1364724071.7300\n",
      "Epoch 27/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -5833507372.7057\n",
      "Epoch 28/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -2309880917.3728\n",
      "Epoch 29/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -1367278890.2194\n",
      "Epoch 30/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -1159602737.4451\n",
      "Epoch 31/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -4794136702.1915\n",
      "Epoch 32/100\n",
      "1273/1273 [==============================] - 1s 902us/step - loss: -12686721637.5055\n",
      "Epoch 33/100\n",
      "1273/1273 [==============================] - 1s 968us/step - loss: -2081472262.8269\n",
      "Epoch 34/100\n",
      "1273/1273 [==============================] - 1s 929us/step - loss: -10665678901.0078\n",
      "Epoch 35/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -5189751356.8424\n",
      "Epoch 36/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -1123487718.2482\n",
      "Epoch 37/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -1377709394.1107\n",
      "Epoch 38/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -24589424835.7904\n",
      "Epoch 39/100\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: -10971641670.1970\n",
      "Epoch 40/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -1276326206.9583\n",
      "Epoch 41/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -2525255205.7174\n",
      "Epoch 42/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -9673299365.3636\n",
      "Epoch 43/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -7377864545.1454A: 0s - loss: -647\n",
      "Epoch 44/100\n",
      "1273/1273 [==============================] - 1s 860us/step - loss: -4424828346.0922\n",
      "Epoch 45/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -7001734891.2543\n",
      "Epoch 46/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -1896387048.4647\n",
      "Epoch 47/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -4903024726.5118\n",
      "Epoch 48/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -32216988210.5039\n",
      "Epoch 49/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -2068698117.5259\n",
      "Epoch 50/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -1243431544.3128\n",
      "Epoch 51/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -13128870367.6754\n",
      "Epoch 52/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -17553985917.6735\n",
      "Epoch 53/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -7837401309.8713\n",
      "Epoch 54/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -2336085576.4396\n",
      "Epoch 55/100\n",
      "1273/1273 [==============================] - 1s 968us/step - loss: -11027405604.2936\n",
      "Epoch 56/100\n",
      "1273/1273 [==============================] - 1s 941us/step - loss: -11618107288.6970\n",
      "Epoch 57/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -42029000778.0856\n",
      "Epoch 58/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -8146521461.2527\n",
      "Epoch 59/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -26482932015.4368\n",
      "Epoch 60/100\n",
      "1273/1273 [==============================] - 1s 859us/step - loss: -3623438113.1052\n",
      "Epoch 61/100\n",
      "1273/1273 [==============================] - 1s 908us/step - loss: -15278473665.0840\n",
      "Epoch 62/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -17977016027.1460: 0s - loss: -18397590\n",
      "Epoch 63/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -22344622314.5808\n",
      "Epoch 64/100\n",
      "1273/1273 [==============================] - 1s 919us/step - loss: -4963464663.8548\n",
      "Epoch 65/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -3306651933.6191 \n",
      "Epoch 66/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -9168930406.1040\n",
      "Epoch 67/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -5675256258.2072A: 0s - loss: -2870024513\n",
      "Epoch 68/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -40308642676.5086\n",
      "Epoch 69/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -31321179106.3979\n",
      "Epoch 70/100\n",
      "1273/1273 [==============================] - 1s 956us/step - loss: -102282567941.6397\n",
      "Epoch 71/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -11635659961.2551\n",
      "Epoch 72/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -11187023749.0000\n",
      "Epoch 73/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -2014145440.5304\n",
      "Epoch 74/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -4765057621.3940\n",
      "Epoch 75/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -51553518057.9921\n",
      "Epoch 76/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -34092743062.6232\n",
      "Epoch 77/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -3598220695.7425\n",
      "Epoch 78/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -7362919916.4101\n",
      "Epoch 79/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -19426116663.2088: 0s - los\n",
      "Epoch 80/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: -82685890753.0361\n",
      "Epoch 81/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -41307935547.7916\n",
      "Epoch 82/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -13403604687.8462\n",
      "Epoch 83/100\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: -36279369348.3328\n",
      "Epoch 84/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -4660018235.8807\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1273/1273 [==============================] - 2s 1ms/step - loss: -8454289936.2386\n",
      "Epoch 86/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -4353215165.6334\n",
      "Epoch 87/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -26755591730.1350\n",
      "Epoch 88/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -48073018652.2323\n",
      "Epoch 89/100\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: -29829917817.5950\n",
      "Epoch 90/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -23617421548.2072\n",
      "Epoch 91/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -10121782453.3626\n",
      "Epoch 92/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -20651801369.2810\n",
      "Epoch 93/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -10190460346.5746\n",
      "Epoch 94/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -10056434908.1570\n",
      "Epoch 95/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -12839224358.6813\n",
      "Epoch 96/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -6898224936.5181\n",
      "Epoch 97/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -44331612153.1554\n",
      "Epoch 98/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -178116390677.9058\n",
      "Epoch 99/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -23918602291.7928\n",
      "Epoch 100/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: -6880175097.7268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa72864d210>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_train, X_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a separate encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_attrs, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 21)]              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                352       \n",
      "=================================================================\n",
      "Total params: 352\n",
      "Trainable params: 352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(encoder.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### derive new non-linear features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nonLinear_features = encoder.predict(X_train)\n",
    "X_test_nonLinear_features = encoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1132.7853, 1210.6514, 1257.5206, 1198.3643, 1139.1997, 1282.446 ,\n",
       "        1219.8794, 1180.4851, 1261.1199, 1225.3845, 1129.0045, 1213.9185,\n",
       "        1248.2655, 1256.0734, 1263.2224, 1233.0189]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_nonLinear_features[1:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[  3.0438576,   3.6714492,   3.4604812,   3.284401 ,   3.0981462,\n",
       "           3.4374838,   3.6635752,   3.053891 ,   3.0580802,   3.5715654,\n",
       "           2.9090643,   3.0019627,   3.6111887,   3.498414 ,   3.7332194,\n",
       "           3.1128902],\n",
       "        [ 20.892052 ,  23.88674  ,  23.930578 ,  22.084517 ,  22.937416 ,\n",
       "          27.233696 ,  24.8992   ,  24.368177 ,  23.799368 ,  23.610823 ,\n",
       "          21.974562 ,  22.886496 ,  24.70836  ,  22.135155 ,  23.65166  ,\n",
       "          23.149393 ],\n",
       "        [  2.8695116,   2.7085586,   2.689878 ,   3.3630993,   2.3891144,\n",
       "           3.5577621,   3.4534807,   3.1380975,   3.4128444,   3.110708 ,\n",
       "           2.9169302,   3.0767474,   3.0892327,   2.970638 ,   3.1258504,\n",
       "           2.8528163],\n",
       "        [  2.7379303,   3.1949327,   3.547045 ,   3.1567545,   3.1136446,\n",
       "           2.8804812,   3.39318  ,   3.332313 ,   3.2128358,   3.0116868,\n",
       "           3.0083053,   3.3608088,   3.2904294,   3.1607378,   3.046194 ,\n",
       "           2.8190832],\n",
       "        [  2.8375728,   2.7369847,   3.1909359,   2.8970296,   3.2439   ,\n",
       "           3.3156679,   2.889328 ,   3.2851908,   3.539469 ,   2.9788268,\n",
       "           3.0509765,   3.1933355,   3.1981165,   3.426754 ,   3.5681834,\n",
       "           3.3166735],\n",
       "        [  3.072405 ,   2.778019 ,   2.8989873,   3.270299 ,   3.0481584,\n",
       "           3.1048853,   2.877903 ,   2.9517891,   3.4317362,   3.1602495,\n",
       "           2.999756 ,   3.0599325,   3.1972666,   3.335029 ,   3.1286972,\n",
       "           3.252584 ],\n",
       "        [  2.9004679,   2.5350027,   3.33438  ,   2.5644472,   2.623589 ,\n",
       "           2.7622771,   3.0426714,   2.399947 ,   2.9996238,   2.7878294,\n",
       "           2.52453  ,   2.9257395,   3.2369764,   3.2749867,   3.584821 ,\n",
       "           2.775398 ],\n",
       "        [  3.4651933,   3.4059718,   3.5059087,   3.8031614,   2.7345335,\n",
       "           3.565013 ,   3.7567613,   2.76866  ,   3.3345804,   3.8287356,\n",
       "           3.3962033,   3.5887928,   3.2548778,   3.1310163,   3.435355 ,\n",
       "           3.5024931],\n",
       "        [  2.7545733,   3.4512072,   3.3798473,   3.581052 ,   3.1166072,\n",
       "           3.0759428,   2.8910372,   2.9418132,   3.4541793,   3.6907094,\n",
       "           2.9573524,   2.960707 ,   3.338741 ,   3.5912104,   3.7644315,\n",
       "           3.3648183],\n",
       "        [  3.3157663,   3.5323756,   3.508176 ,   2.8628633,   2.4476862,\n",
       "           3.601745 ,   3.3124256,   2.9139588,   3.0840342,   3.019418 ,\n",
       "           2.6263974,   3.2489717,   3.1563168,   3.468803 ,   3.1106973,\n",
       "           3.3831735],\n",
       "        [  2.590455 ,   2.8470678,   3.3244715,   3.337145 ,   3.0934634,\n",
       "           3.5289912,   2.9864912,   2.859332 ,   3.5101285,   2.7966344,\n",
       "           3.279983 ,   3.2607977,   3.4321609,   3.2318883,   3.4854445,\n",
       "           2.9953272],\n",
       "        [ 12.44215  ,  14.518021 ,  13.932146 ,  13.991723 ,  12.996099 ,\n",
       "          13.752281 ,  13.732236 ,  12.867647 ,  13.644446 ,  14.879118 ,\n",
       "          13.182573 ,  14.211085 ,  14.54967  ,  14.529985 ,  14.338984 ,\n",
       "          14.406237 ],\n",
       "        [ -6.455637 ,  -8.815231 ,  -9.429694 ,  -7.8409925,  -8.861783 ,\n",
       "         -11.48041  , -10.946807 ,  -8.253814 ,  -8.839173 , -10.593131 ,\n",
       "         -10.011946 ,  -7.3163104, -10.156659 ,  -6.830724 ,  -9.111112 ,\n",
       "          -7.0888996],\n",
       "        [ -3.8605983,  -5.4551005,  -5.452542 ,  -3.9166093,  -6.2608075,\n",
       "          -7.7732983,  -7.8109207,  -5.4084325,  -5.688068 ,  -6.541874 ,\n",
       "          -6.257827 ,  -3.9908895,  -6.792497 ,  -3.1085463,  -5.4626684,\n",
       "          -3.7681413],\n",
       "        [ 12.395101 ,  14.136029 ,  14.233583 ,  14.1189575,  13.320591 ,\n",
       "          13.569898 ,  13.742667 ,  13.156944 ,  14.0482435,  13.987727 ,\n",
       "          13.508115 ,  13.790383 ,  14.315506 ,  14.324502 ,  14.241408 ,\n",
       "          14.567504 ],\n",
       "        [  4.132988 ,   5.7098594,   5.394259 ,   5.500103 ,   4.5761547,\n",
       "           5.364379 ,   5.061327 ,   4.639763 ,   5.1104894,   6.007785 ,\n",
       "           4.9957943,   5.0511017,   5.6355896,   5.2685356,   5.225742 ,\n",
       "           4.6656632],\n",
       "        [ 21.573267 ,  27.454275 ,  25.275507 ,  23.107998 ,  23.638935 ,\n",
       "          30.207659 ,  27.661306 ,  23.692484 ,  25.022346 ,  28.889322 ,\n",
       "          24.008131 ,  23.92458  ,  28.165512 ,  22.215157 ,  25.096567 ,\n",
       "          22.574184 ],\n",
       "        [  8.590846 ,   9.39724  ,   9.2903385,   8.98162  ,   8.666479 ,\n",
       "           9.731363 ,   9.741636 ,   8.871473 ,   9.035416 ,   9.100965 ,\n",
       "           8.5769205,   8.884699 ,   9.066017 ,   9.013623 ,   9.511254 ,\n",
       "           9.711228 ],\n",
       "        [ 23.031176 ,  29.382763 ,  27.843197 ,  27.907341 ,  26.22587  ,\n",
       "          29.162653 ,  28.643442 ,  25.589247 ,  27.467646 ,  30.392218 ,\n",
       "          27.04219  ,  27.567358 ,  29.344265 ,  27.562044 ,  28.237263 ,\n",
       "          26.694077 ],\n",
       "        [ 21.70259  ,  25.454557 ,  25.386375 ,  24.797487 ,  24.26131  ,\n",
       "          28.70416  ,  26.257257 ,  25.716677 ,  26.12342  ,  25.705875 ,\n",
       "          24.093285 ,  25.359983 ,  26.243383 ,  24.883871 ,  26.011887 ,\n",
       "          25.420963 ],\n",
       "        [  3.9168377,   4.2774763,   4.013693 ,   3.6226234,   3.5627294,\n",
       "           4.1837683,   4.4179997,   3.9826524,   3.9353518,   4.311611 ,\n",
       "           3.5377493,   4.165051 ,   4.2646327,   3.4740527,   4.2134056,\n",
       "           4.467307 ]], dtype=float32),\n",
       " array([22.613201, 26.347233, 26.393276, 25.370787, 25.191889, 29.065548,\n",
       "        26.9817  , 26.148275, 26.718927, 26.542297, 24.588371, 25.67802 ,\n",
       "        26.88793 , 25.30134 , 26.719961, 25.825127], dtype=float32)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining new non-linear features to X_train and X_test respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train, X_train_nonLinear_features), axis=1)\n",
    "X_test = np.concatenate((X_test, X_test_nonLinear_features), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron Model Building with both actual and non-linear features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_model = Sequential()\n",
    "\n",
    "perceptron_model.add(Dense(1, input_dim=X_train.shape[1], activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 2420.1597\n",
      "Epoch 2/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 39.5215\n",
      "Epoch 3/100\n",
      "1273/1273 [==============================] - 1s 954us/step - loss: 74.7435\n",
      "Epoch 4/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 40.1136\n",
      "Epoch 5/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 46.7896\n",
      "Epoch 6/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 23.5892\n",
      "Epoch 7/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 33.7747\n",
      "Epoch 8/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 41.1347\n",
      "Epoch 9/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 11.6426\n",
      "Epoch 10/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 27.0195\n",
      "Epoch 11/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 96.2471\n",
      "Epoch 12/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 100.4280\n",
      "Epoch 13/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 53.1031\n",
      "Epoch 14/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 91.1162\n",
      "Epoch 15/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 87.3666\n",
      "Epoch 16/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 10.2450\n",
      "Epoch 17/100\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 34.1310\n",
      "Epoch 18/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 42.7354\n",
      "Epoch 19/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 30.4438\n",
      "Epoch 20/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 9.8449\n",
      "Epoch 21/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 59.8385\n",
      "Epoch 22/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 25.3095\n",
      "Epoch 23/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 21.5557\n",
      "Epoch 24/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 38.0437\n",
      "Epoch 25/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 20.9640\n",
      "Epoch 26/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 43.0227\n",
      "Epoch 27/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 12.3233\n",
      "Epoch 28/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 36.7788\n",
      "Epoch 29/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 6.2346\n",
      "Epoch 30/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 32.2609\n",
      "Epoch 31/100\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 25.4548\n",
      "Epoch 32/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 28.9537\n",
      "Epoch 33/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 41.2256\n",
      "Epoch 34/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 22.7052\n",
      "Epoch 35/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 44.0540\n",
      "Epoch 36/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 9.9173\n",
      "Epoch 37/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 22.3418\n",
      "Epoch 38/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 20.3079\n",
      "Epoch 39/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 15.2819\n",
      "Epoch 40/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 42.3650\n",
      "Epoch 41/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 30.0768\n",
      "Epoch 42/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 25.0325\n",
      "Epoch 43/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 26.5853\n",
      "Epoch 44/100\n",
      "1273/1273 [==============================] - 1s 939us/step - loss: 39.3866\n",
      "Epoch 45/100\n",
      "1273/1273 [==============================] - 1s 948us/step - loss: 27.4904\n",
      "Epoch 46/100\n",
      "1273/1273 [==============================] - 1s 917us/step - loss: 18.1917\n",
      "Epoch 47/100\n",
      "1273/1273 [==============================] - 1s 794us/step - loss: 33.2926\n",
      "Epoch 48/100\n",
      "1273/1273 [==============================] - 1s 939us/step - loss: 35.3134\n",
      "Epoch 49/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 27.8208\n",
      "Epoch 50/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 66.4148\n",
      "Epoch 51/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 19.0676\n",
      "Epoch 52/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 158.0997\n",
      "Epoch 53/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 23.1475\n",
      "Epoch 54/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 8.9420\n",
      "Epoch 55/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 17.3761\n",
      "Epoch 56/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 10.3168\n",
      "Epoch 57/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 14.5412\n",
      "Epoch 58/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 21.4738\n",
      "Epoch 59/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 26.5578\n",
      "Epoch 60/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 13.6064\n",
      "Epoch 61/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 16.6103\n",
      "Epoch 62/100\n",
      "1273/1273 [==============================] - 1s 968us/step - loss: 243.4488\n",
      "Epoch 63/100\n",
      "1273/1273 [==============================] - 1s 948us/step - loss: 14.8265\n",
      "Epoch 64/100\n",
      "1273/1273 [==============================] - 1s 890us/step - loss: 32.6191\n",
      "Epoch 65/100\n",
      "1273/1273 [==============================] - 1s 996us/step - loss: 15.9139\n",
      "Epoch 66/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 17.3775\n",
      "Epoch 67/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 63.7676\n",
      "Epoch 68/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 28.3507\n",
      "Epoch 69/100\n",
      "1273/1273 [==============================] - 1s 998us/step - loss: 115.4775\n",
      "Epoch 70/100\n",
      "1273/1273 [==============================] - 1s 857us/step - loss: 60.9637\n",
      "Epoch 71/100\n",
      "1273/1273 [==============================] - 1s 958us/step - loss: 23.6674\n",
      "Epoch 72/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 9.7264\n",
      "Epoch 73/100\n",
      "1273/1273 [==============================] - 1s 979us/step - loss: 36.3307\n",
      "Epoch 74/100\n",
      "1273/1273 [==============================] - 1s 995us/step - loss: 34.3330\n",
      "Epoch 75/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 18.4940\n",
      "Epoch 76/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 40.7312\n",
      "Epoch 77/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 9.1185\n",
      "Epoch 78/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 18.1530\n",
      "Epoch 79/100\n",
      "1273/1273 [==============================] - 1s 928us/step - loss: 21.2285\n",
      "Epoch 80/100\n",
      "1273/1273 [==============================] - 1s 926us/step - loss: 15.2239\n",
      "Epoch 81/100\n",
      "1273/1273 [==============================] - 1s 962us/step - loss: 28.7566\n",
      "Epoch 82/100\n",
      "1273/1273 [==============================] - 1s 904us/step - loss: 14.7403\n",
      "Epoch 83/100\n",
      "1273/1273 [==============================] - 1s 850us/step - loss: 39.4285\n",
      "Epoch 84/100\n",
      "1273/1273 [==============================] - 1s 879us/step - loss: 24.2264\n",
      "Epoch 85/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 63.6500\n",
      "Epoch 86/100\n",
      "1273/1273 [==============================] - 1s 932us/step - loss: 14.9141\n",
      "Epoch 87/100\n",
      "1273/1273 [==============================] - 1s 911us/step - loss: 26.3997\n",
      "Epoch 88/100\n",
      "1273/1273 [==============================] - 1s 811us/step - loss: 23.9125\n",
      "Epoch 89/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 17.9923\n",
      "Epoch 90/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 51.8010\n",
      "Epoch 91/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 25.9584\n",
      "Epoch 92/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 368.3496\n",
      "Epoch 93/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 4.8305\n",
      "Epoch 94/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 13.0398\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1273/1273 [==============================] - 1s 1ms/step - loss: 13.6043\n",
      "Epoch 96/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 22.1022\n",
      "Epoch 97/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 38.3838\n",
      "Epoch 98/100\n",
      "1273/1273 [==============================] - 1s 1ms/step - loss: 24.7133\n",
      "Epoch 99/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 15.5535\n",
      "Epoch 100/100\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 24.9712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa7285e8690>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron_model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "test_pred=perceptron_model.predict_classes(X_test)\n",
    "train_pred=perceptron_model.predict_classes(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting evaluation metrics and evaluating model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33067     0]\n",
      " [ 7663     0]]\n",
      "[[14149     1]\n",
      " [ 3306     0]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_test = confusion_matrix(y_test, test_pred)\n",
    "confusion_matrix_train = confusion_matrix(y_train, train_pred)\n",
    "\n",
    "print(confusion_matrix_train)\n",
    "print(confusion_matrix_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Accuracy, True Positive Rate and True Negative Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train TNR:  1.0\n",
      "Train TPR:  0.0\n",
      "Train Accuracy:  0.8118585808986005\n"
     ]
    }
   ],
   "source": [
    "Accuracy_Train=(confusion_matrix_train[0,0]+confusion_matrix_train[1,1])/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1]+confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "TNR_Train= confusion_matrix_train[0,0]/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1])\n",
    "TPR_Train= confusion_matrix_train[1,1]/(confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "\n",
    "print(\"Train TNR: \",TNR_Train)\n",
    "print(\"Train TPR: \",TPR_Train)\n",
    "print(\"Train Accuracy: \",Accuracy_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test TNR:  0.9999293286219081\n",
      "Test TPR:  0.0\n",
      "Test Accuracy:  0.8105522456461961\n"
     ]
    }
   ],
   "source": [
    "Accuracy_Test=(confusion_matrix_test[0,0]+confusion_matrix_test[1,1])/(confusion_matrix_test[0,0]+confusion_matrix_test[0,1]+confusion_matrix_test[1,0]+confusion_matrix_test[1,1])\n",
    "TNR_Test= confusion_matrix_test[0,0]/(confusion_matrix_test[0,0] +confusion_matrix_test[0,1])\n",
    "TPR_Test= confusion_matrix_test[1,1]/(confusion_matrix_test[1,0] +confusion_matrix_test[1,1])\n",
    "\n",
    "print(\"Test TNR: \",TNR_Test)\n",
    "print(\"Test TPR: \",TPR_Test)\n",
    "print(\"Test Accuracy: \",Accuracy_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
